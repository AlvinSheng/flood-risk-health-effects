---
title: "Basic CAR Model"
author: "Alvin Sheng"
output: pdf_document
---

```{r}
library(here)
library(coda)
library(CARBayes)
library(ggplot2)
library(tidyverse)
```

```{r}
i_am("reports/basic_CAR_model_all_census_tract.Rmd")
```

```{r}
fhs_model_df <- readRDS("intermediary_data/fhs_model_df_all_census_tract_pc.rds")
```



# CAR model results, Coronary Heart Disease

Inference is based on 3 markov chains, each of which has been run for 110000 samples, the first 10000 of which has been removed for burn-in. The remaining 100000 samples are thinned by 2, resulting in 150000 samples for inference across the 3 Markov chains. 

```{r}
load(here("modeling_files/all_census_tract_intrinsic.RData"))
```

## Model Diagnostics

## Residual Plots

For each chain

```{r}
plot(chain1$mean.fitted, chain1$residuals$pearson)

abline(h = 0, col = "red")
```

```{r}
plot(chain2$mean.fitted, chain2$residuals$pearson)

abline(h = 0, col = "red")
```

```{r}
plot(chain3$mean.fitted, chain3$residuals$pearson)

abline(h = 0, col = "red")
```

```{r}
qqnorm(chain1$residuals$pearson)

qqline(chain1$residuals$pearson)
```

What's the proportion of predicted values that correspond to negative counts? Which would not make sense

```{r}
mean(chain1$mean.fitted < 0, na.rm = T)
```

Small proportion seems reasonable. 



### Beta samples

```{r}
beta_samples <- mcmc.list(chain1$samples$beta, chain2$samples$beta, 
                          chain3$samples$beta)
```

```{r}
effectiveSize(beta_samples)
```

```{r, eval = F}
plot(beta_samples)
```

```{r}
gelman.diag(beta_samples)
```




### Examining sigma2, nu2, rho

```{r}
sigma2_samples <- mcmc.list(chain1$samples$sigma2, chain2$samples$sigma2, 
                            chain3$samples$sigma2)

nu2_samples <- mcmc.list(chain1$samples$nu2, chain2$samples$nu2, 
                         chain3$samples$nu2)

```

```{r, eval = F}
plot(sigma2_samples)

plot(nu2_samples)
```

```{r}
gelman.diag(sigma2_samples)
```

```{r}
gelman.diag(nu2_samples)
```



### Examining a sample of the 3108 phi parameters

```{r}
phi_samples <- mcmc.list(chain1$samples$phi, chain2$samples$phi, chain3$samples$phi)
```

```{r}
set.seed(1157, kind = "Mersenne-Twister", normal.kind = "Inversion", sample.kind = "Rejection")

phi_subset_idx <- sample(1:ncol(phi_samples[[1]]), size = 10)

phi_samples_subset <- phi_samples[, phi_subset_idx]
```

```{r, eval = F}
plot(phi_samples_subset)
```

```{r}
gelman.diag(phi_samples_subset)
```



## Inference

```{r}
beta_samples_matrix <- rbind(chain1$samples$beta, chain2$samples$beta, chain3$samples$beta)

colnames(beta_samples_matrix) <- c("Intercept", names(fhs_model_df[, 14:(ncol(fhs_model_df) - 4)]))
```

```{r}
(beta_inference <- round(t(apply(beta_samples_matrix, 2, quantile, c(0.5, 0.025, 0.975))),5))
```

<!-- Net Effect interpretation: what if each variable in a group (flood risk variables, SVIs, air pollution variables) increased by 1 standard deviation? What is the resulting change in the dependent variable? -->

<!-- ```{r} -->

<!-- sum(beta_inference[2:7, 1]) -->
<!-- sum(beta_inference[2:22, 1]) -->
<!-- sum(beta_inference[23:38, 1]) -->
<!-- sum(beta_inference[39:44, 1]) -->

<!-- ``` -->

List of significant beta coefficients: 

```{r}
colnames(beta_samples_matrix)[sign(beta_inference[, 2]) == sign(beta_inference[, 3])]
```



### Credible Interval plots for the coefficients, in ggplot

```{r}
# first, process the beta_inference matrix in a form ggplot can understand

beta_inference_df <- as.data.frame(beta_inference)

beta_inference_df <- mutate(beta_inference_df, var_name = row.names(beta_inference_df))

beta_inference_df <- rename(beta_inference_df, 
                            post_median = `50%`,
                            post_2.5 = `2.5%`, 
                            post_97.5 = `97.5%`)

beta_inference_df$var_name <- factor(beta_inference_df$var_name, levels = beta_inference_df$var_name)
```

```{r}
p <- ggplot(beta_inference_df[-1, ], aes(x = var_name, y = post_median)) + 
  geom_point() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1), axis.title.x = element_blank(), axis.title.y = element_blank(), 
        axis.text=element_text(size=12), 
        plot.margin = margin(5.5, 5.5, 5.5, 10)) +
  geom_errorbar(aes(ymin = post_2.5, ymax = post_97.5, width = 0.4)) + 
  geom_vline(xintercept = c(5.5, 21.5, 27.5, 31.5), col = "blue") +
  geom_hline(yintercept = 0, col = "red") +
  annotate(geom = "text", x = 3.5, y = 1.45, label = "Flood\nRisk",
           col = "blue", size = 4.5) +
  annotate(geom = "text", x = 13.5, y = 1.5, label = "Social Vulnerability Index",
           col = "blue", size = 4.5) +
  annotate(geom = "text", x = 24.5, y = 1.5, label = "Air Pollution",
           col = "blue", size = 4.5) +
  annotate(geom = "text", x = 29.5, y = 1.5, label = "GRIDMET",
           col = "blue", size = 4.5) +
  scale_x_discrete(labels = c("PC 1", "PC 2", "PC 3", "PC 4", "PC 5",
                              "Poverty", "Unemployed", "Per Capita Income", "No High School",
                              "65 or Over", "17 or Under", "Disability",
                              "Single-Parent", "Minority", "Poor English",
                              "Multi-Unit", "Mobile", "Crowded",
                              "No Vehicle", "Group Quarters", "Uninsured",
                              "CO", "NO2", "O3", "PM10", "PM2.5", "SO2",
                              "Summer Temperature", "Winter Temperature", "Summer Humidity", "Winter Humidity",
                              "Smoking")) + ggtitle("95% Credible Intervals of Coefficients, Coronary Heart Disease")

p
```



# CAR model results, High Blood Pressure

Inference is based on 3 markov chains, each of which has been run for 110000 samples, the first 10000 of which has been removed for burn-in. The remaining 100000 samples are thinned by 2, resulting in 150000 samples for inference across the 3 Markov chains. 

```{r}
load(here("modeling_files/all_census_tract_BPHIGH.RData"))
```

## Model Diagnostics

### Residual plot

```{r}
plot(chain1$mean.fitted, chain1$residuals$pearson)

abline(h = 0, col = "red")
```

```{r}
qqnorm(chain1$residuals$pearson)

qqline(chain1$residuals$pearson)
```



### Beta samples

```{r}
beta_samples <- mcmc.list(chain1$samples$beta, chain2$samples$beta, 
                          chain3$samples$beta)
```

```{r}
effectiveSize(beta_samples)
```

```{r, eval = F}
plot(beta_samples)
```

```{r}
gelman.diag(beta_samples)
```




### Examining sigma2, nu2, rho

```{r}
sigma2_samples <- mcmc.list(chain1$samples$sigma2, chain2$samples$sigma2, 
                            chain3$samples$sigma2)

nu2_samples <- mcmc.list(chain1$samples$nu2, chain2$samples$nu2, 
                         chain3$samples$nu2)

```

```{r, eval = F}
plot(sigma2_samples)

plot(nu2_samples)
```

```{r}
gelman.diag(sigma2_samples)
```

```{r}
gelman.diag(nu2_samples)
```



### Examining a sample of the 3108 phi parameters

```{r}
phi_samples <- mcmc.list(chain1$samples$phi, chain2$samples$phi, chain3$samples$phi)
```

```{r}
set.seed(1157, kind = "Mersenne-Twister", normal.kind = "Inversion", sample.kind = "Rejection")

phi_subset_idx <- sample(1:ncol(phi_samples[[1]]), size = 10)

phi_samples_subset <- phi_samples[, phi_subset_idx]
```

```{r, eval = F}
plot(phi_samples_subset)
```

```{r}
gelman.diag(phi_samples_subset)
```



## Inference

```{r}
beta_samples_matrix <- rbind(chain1$samples$beta, chain2$samples$beta, chain3$samples$beta)

colnames(beta_samples_matrix) <- c("Intercept", names(fhs_model_df[, 14:(ncol(fhs_model_df) - 4)]))
```

```{r}
(beta_inference <- round(t(apply(beta_samples_matrix, 2, quantile, c(0.5, 0.025, 0.975))),5))
```

<!-- Net Effect interpretation: what if each variable in a group (flood risk variables, SVIs, air pollution variables) increased by 1 standard deviation? What is the resulting change in the dependent variable? -->

<!-- ```{r} -->

<!-- sum(beta_inference[2:7, 1]) -->
<!-- sum(beta_inference[2:22, 1]) -->
<!-- sum(beta_inference[23:38, 1]) -->
<!-- sum(beta_inference[39:44, 1]) -->

<!-- ``` -->

List of significant beta coefficients: 

```{r}
colnames(beta_samples_matrix)[sign(beta_inference[, 2]) == sign(beta_inference[, 3])]
```



### Credible Interval plots for the coefficients, in ggplot

```{r}
# first, process the beta_inference matrix in a form ggplot can understand

beta_inference_df <- as.data.frame(beta_inference)

beta_inference_df <- mutate(beta_inference_df, var_name = row.names(beta_inference_df))

beta_inference_df <- rename(beta_inference_df, 
                            post_median = `50%`,
                            post_2.5 = `2.5%`, 
                            post_97.5 = `97.5%`)

beta_inference_df$var_name <- factor(beta_inference_df$var_name, levels = beta_inference_df$var_name)
```

```{r}
p <- ggplot(beta_inference_df[-1, ], aes(x = var_name, y = post_median)) + 
  geom_point() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1), axis.title.x = element_blank(), axis.title.y = element_blank(), 
        axis.text=element_text(size=12), 
        plot.margin = margin(5.5, 5.5, 5.5, 10)) +
  geom_errorbar(aes(ymin = post_2.5, ymax = post_97.5, width = 0.4)) + 
  geom_vline(xintercept = c(5.5, 21.5, 27.5, 31.5), col = "blue") +
  geom_hline(yintercept = 0, col = "red") +
  annotate(geom = "text", x = 3.5, y = 1.45, label = "Flood\nRisk",
           col = "blue", size = 4.5) +
  annotate(geom = "text", x = 13.5, y = 1.5, label = "Social Vulnerability Index",
           col = "blue", size = 4.5) +
  annotate(geom = "text", x = 24.5, y = 1.5, label = "Air Pollution",
           col = "blue", size = 4.5) +
  annotate(geom = "text", x = 29.5, y = 1.5, label = "GRIDMET",
           col = "blue", size = 4.5) +
  scale_x_discrete(labels = c("PC 1", "PC 2", "PC 3", "PC 4", "PC 5",
                              "Poverty", "Unemployed", "Per Capita Income", "No High School",
                              "65 or Over", "17 or Under", "Disability",
                              "Single-Parent", "Minority", "Poor English",
                              "Multi-Unit", "Mobile", "Crowded",
                              "No Vehicle", "Group Quarters", "Uninsured",
                              "CO", "NO2", "O3", "PM10", "PM2.5", "SO2",
                              "Summer Temperature", "Winter Temperature", "Summer Humidity", "Winter Humidity",
                              "Smoking")) + ggtitle("95% Credible Intervals of Coefficients, High Blood Pressure")

p
```



# CAR model results, Asthma

Inference is based on 3 markov chains, each of which has been run for 110000 samples, the first 10000 of which has been removed for burn-in. The remaining 100000 samples are thinned by 2, resulting in 150000 samples for inference across the 3 Markov chains. 

```{r}
load(here("modeling_files/all_census_tract_CASTHMA.RData"))
```

## Model Diagnostics

### Residual plot

```{r}
plot(chain1$mean.fitted, chain1$residuals$pearson)

abline(h = 0, col = "red")
```

```{r}
qqnorm(chain1$residuals$pearson)

qqline(chain1$residuals$pearson)
```



### Beta samples

```{r}
beta_samples <- mcmc.list(chain1$samples$beta, chain2$samples$beta, 
                          chain3$samples$beta)
```

```{r}
effectiveSize(beta_samples)
```

```{r, eval = F}
plot(beta_samples)
```

```{r}
gelman.diag(beta_samples)
```




### Examining sigma2, nu2, rho

```{r}
sigma2_samples <- mcmc.list(chain1$samples$sigma2, chain2$samples$sigma2, 
                            chain3$samples$sigma2)

nu2_samples <- mcmc.list(chain1$samples$nu2, chain2$samples$nu2, 
                         chain3$samples$nu2)

```

```{r, eval = F}
plot(sigma2_samples)

plot(nu2_samples)
```

```{r}
gelman.diag(sigma2_samples)
```

```{r}
gelman.diag(nu2_samples)
```



### Examining a sample of the 3108 phi parameters

```{r}
phi_samples <- mcmc.list(chain1$samples$phi, chain2$samples$phi, chain3$samples$phi)
```

```{r}
set.seed(1157, kind = "Mersenne-Twister", normal.kind = "Inversion", sample.kind = "Rejection")

phi_subset_idx <- sample(1:ncol(phi_samples[[1]]), size = 10)

phi_samples_subset <- phi_samples[, phi_subset_idx]
```

```{r, eval = F}
plot(phi_samples_subset)
```

```{r}
gelman.diag(phi_samples_subset)
```



## Inference

```{r}
beta_samples_matrix <- rbind(chain1$samples$beta, chain2$samples$beta, chain3$samples$beta)

colnames(beta_samples_matrix) <- c("Intercept", names(fhs_model_df[, 14:(ncol(fhs_model_df) - 4)]))
```

```{r}
(beta_inference <- round(t(apply(beta_samples_matrix, 2, quantile, c(0.5, 0.025, 0.975))),5))
```

<!-- Net Effect interpretation: what if each variable in a group (flood risk variables, SVIs, air pollution variables) increased by 1 standard deviation? What is the resulting change in the dependent variable? -->

<!-- ```{r} -->

<!-- sum(beta_inference[2:7, 1]) -->
<!-- sum(beta_inference[2:22, 1]) -->
<!-- sum(beta_inference[23:38, 1]) -->
<!-- sum(beta_inference[39:44, 1]) -->

<!-- ``` -->

List of significant beta coefficients: 

```{r}
colnames(beta_samples_matrix)[sign(beta_inference[, 2]) == sign(beta_inference[, 3])]
```



### Credible Interval plots for the coefficients, in ggplot

```{r}
# first, process the beta_inference matrix in a form ggplot can understand

beta_inference_df <- as.data.frame(beta_inference)

beta_inference_df <- mutate(beta_inference_df, var_name = row.names(beta_inference_df))

beta_inference_df <- rename(beta_inference_df, 
                            post_median = `50%`,
                            post_2.5 = `2.5%`, 
                            post_97.5 = `97.5%`)

beta_inference_df$var_name <- factor(beta_inference_df$var_name, levels = beta_inference_df$var_name)
```

```{r}
p <- ggplot(beta_inference_df[-1, ], aes(x = var_name, y = post_median)) + 
  geom_point() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1), axis.title.x = element_blank(), axis.title.y = element_blank(), 
        axis.text=element_text(size=12), 
        plot.margin = margin(5.5, 5.5, 5.5, 10)) +
  geom_errorbar(aes(ymin = post_2.5, ymax = post_97.5, width = 0.4)) + 
  geom_vline(xintercept = c(5.5, 21.5, 27.5, 31.5), col = "blue") +
  geom_hline(yintercept = 0, col = "red") +
  annotate(geom = "text", x = 3.5, y = 1.45, label = "Flood\nRisk",
           col = "blue", size = 4.5) +
  annotate(geom = "text", x = 13.5, y = 1.5, label = "Social Vulnerability Index",
           col = "blue", size = 4.5) +
  annotate(geom = "text", x = 24.5, y = 1.5, label = "Air Pollution",
           col = "blue", size = 4.5) +
  annotate(geom = "text", x = 29.5, y = 1.5, label = "GRIDMET",
           col = "blue", size = 4.5) +
  scale_x_discrete(labels = c("PC 1", "PC 2", "PC 3", "PC 4", "PC 5",
                              "Poverty", "Unemployed", "Per Capita Income", "No High School",
                              "65 or Over", "17 or Under", "Disability",
                              "Single-Parent", "Minority", "Poor English",
                              "Multi-Unit", "Mobile", "Crowded",
                              "No Vehicle", "Group Quarters", "Uninsured",
                              "CO", "NO2", "O3", "PM10", "PM2.5", "SO2",
                              "Summer Temperature", "Winter Temperature", "Summer Humidity", "Winter Humidity",
                              "Smoking")) + ggtitle("95% Credible Intervals of Coefficients, Asthma")

p
```



# CAR model results, Poor Mental Health

Inference is based on 3 markov chains, each of which has been run for 110000 samples, the first 10000 of which has been removed for burn-in. The remaining 100000 samples are thinned by 2, resulting in 150000 samples for inference across the 3 Markov chains. 

```{r}
load(here("modeling_files/all_census_tract_MHLTH.RData"))
```

## Model Diagnostics

### Residual plot

```{r}
plot(chain1$mean.fitted, chain1$residuals$pearson)

abline(h = 0, col = "red")
```

```{r}
qqnorm(chain1$residuals$pearson)

qqline(chain1$residuals$pearson)
```



### Beta samples

```{r}
beta_samples <- mcmc.list(chain1$samples$beta, chain2$samples$beta, 
                          chain3$samples$beta)
```

```{r}
effectiveSize(beta_samples)
```

```{r, eval = F}
plot(beta_samples)
```

```{r}
gelman.diag(beta_samples)
```




### Examining sigma2, nu2, rho

```{r}
sigma2_samples <- mcmc.list(chain1$samples$sigma2, chain2$samples$sigma2, 
                            chain3$samples$sigma2)

nu2_samples <- mcmc.list(chain1$samples$nu2, chain2$samples$nu2, 
                         chain3$samples$nu2)

```

```{r, eval = F}
plot(sigma2_samples)

plot(nu2_samples)
```

```{r}
gelman.diag(sigma2_samples)
```

```{r}
gelman.diag(nu2_samples)
```



### Examining a sample of the 3108 phi parameters

```{r}
phi_samples <- mcmc.list(chain1$samples$phi, chain2$samples$phi, chain3$samples$phi)
```

```{r}
set.seed(1157, kind = "Mersenne-Twister", normal.kind = "Inversion", sample.kind = "Rejection")

phi_subset_idx <- sample(1:ncol(phi_samples[[1]]), size = 10)

phi_samples_subset <- phi_samples[, phi_subset_idx]
```

```{r, eval = F}
plot(phi_samples_subset)
```

```{r}
gelman.diag(phi_samples_subset)
```



## Inference

```{r}
beta_samples_matrix <- rbind(chain1$samples$beta, chain2$samples$beta, chain3$samples$beta)

colnames(beta_samples_matrix) <- c("Intercept", names(fhs_model_df[, 14:(ncol(fhs_model_df) - 4)]))
```

```{r}
(beta_inference <- round(t(apply(beta_samples_matrix, 2, quantile, c(0.5, 0.025, 0.975))),5))
```

<!-- Net Effect interpretation: what if each variable in a group (flood risk variables, SVIs, air pollution variables) increased by 1 standard deviation? What is the resulting change in the dependent variable? -->

<!-- ```{r} -->

<!-- sum(beta_inference[2:7, 1]) -->
<!-- sum(beta_inference[2:22, 1]) -->
<!-- sum(beta_inference[23:38, 1]) -->
<!-- sum(beta_inference[39:44, 1]) -->

<!-- ``` -->

List of significant beta coefficients: 

```{r}
colnames(beta_samples_matrix)[sign(beta_inference[, 2]) == sign(beta_inference[, 3])]
```



### Credible Interval plots for the coefficients, in ggplot

```{r}
# first, process the beta_inference matrix in a form ggplot can understand

beta_inference_df <- as.data.frame(beta_inference)

beta_inference_df <- mutate(beta_inference_df, var_name = row.names(beta_inference_df))

beta_inference_df <- rename(beta_inference_df, 
                            post_median = `50%`,
                            post_2.5 = `2.5%`, 
                            post_97.5 = `97.5%`)

beta_inference_df$var_name <- factor(beta_inference_df$var_name, levels = beta_inference_df$var_name)
```

```{r}
p <- ggplot(beta_inference_df[-1, ], aes(x = var_name, y = post_median)) + 
  geom_point() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1), axis.title.x = element_blank(), axis.title.y = element_blank(), 
        axis.text=element_text(size=12), 
        plot.margin = margin(5.5, 5.5, 5.5, 10)) +
  geom_errorbar(aes(ymin = post_2.5, ymax = post_97.5, width = 0.4)) + 
  geom_vline(xintercept = c(5.5, 21.5, 27.5, 31.5), col = "blue") +
  geom_hline(yintercept = 0, col = "red") +
  annotate(geom = "text", x = 3.5, y = 1.45, label = "Flood\nRisk",
           col = "blue", size = 4.5) +
  annotate(geom = "text", x = 13.5, y = 1.5, label = "Social Vulnerability Index",
           col = "blue", size = 4.5) +
  annotate(geom = "text", x = 24.5, y = 1.5, label = "Air Pollution",
           col = "blue", size = 4.5) +
  annotate(geom = "text", x = 29.5, y = 1.5, label = "GRIDMET",
           col = "blue", size = 4.5) +
  scale_x_discrete(labels = c("PC 1", "PC 2", "PC 3", "PC 4", "PC 5",
                              "Poverty", "Unemployed", "Per Capita Income", "No High School",
                              "65 or Over", "17 or Under", "Disability",
                              "Single-Parent", "Minority", "Poor English",
                              "Multi-Unit", "Mobile", "Crowded",
                              "No Vehicle", "Group Quarters", "Uninsured",
                              "CO", "NO2", "O3", "PM10", "PM2.5", "SO2",
                              "Summer Temperature", "Winter Temperature", "Summer Humidity", "Winter Humidity",
                              "Smoking")) + ggtitle("95% Credible Intervals of Coefficients, Poor Mental Health")

p
```


