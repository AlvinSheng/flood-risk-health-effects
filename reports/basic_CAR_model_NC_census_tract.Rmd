---
title: "Basic CAR Model"
author: "Alvin Sheng"
date: "6/30/2021"
output: pdf_document
---

```{r}
library(here)
library(coda)
library(CARBayes)
library(ggplot2)
```

```{r}
i_am("reports/basic_CAR_model_NC_census_tract.Rmd")
```

# CAR model results

Inference is based on 3 markov chains, each of which has been run for 100000 samples, the first 10000 of which has been removed for burn-in. The remaining 90000 samples are thinned by 5, resulting in 18000 * 3 = 54000 samples for inference across the 3 Markov chains. 

```{r}
load(here("modeling_files/model_3chains_model_sw_states_census_tract_fr_zip.RData"))
```

Output for the first chain is shown below.

```{r}
chain1
```

The smallest effective sample size is 935.8, for ozone (o3). 

```{r}
chain1$accept
```

It appears that beta, phi, nu2, and tau2 probably have Gibbs steps, whereas rho has a Metropolis-Hastings step. In any case, the acceptance probabilities are acceptable. 



## Model Diagnostics

### Beta samples

```{r}
beta_samples <- mcmc.list(chain1$samples$beta, chain2$samples$beta, 
                          chain3$samples$beta)
```

```{r}
plot(beta_samples)
```

```{r}
gelman.diag(beta_samples)
```




### Examining tau2, nu2, rho

```{r}
tau2_samples <- mcmc.list(chain1$samples$tau2, chain2$samples$tau2, 
                          chain3$samples$tau2)

nu2_samples <- mcmc.list(chain1$samples$nu2, chain2$samples$nu2, 
                          chain3$samples$nu2)

rho_samples <- mcmc.list(chain1$samples$rho, chain2$samples$rho, 
                          chain3$samples$rho) 

```

```{r}
plot(tau2_samples)

plot(nu2_samples)

plot(rho_samples)
```

```{r}
gelman.diag(tau2_samples)
```

```{r}
gelman.diag(nu2_samples)
```

```{r}
gelman.diag(rho_samples)
```



### Examining a sample of the 3108 phi parameters

```{r}
phi_samples <- mcmc.list(chain1$samples$phi, chain2$samples$phi, chain3$samples$phi)
```

```{r}
set.seed(1157, kind = "Mersenne-Twister", normal.kind = "Inversion", sample.kind = "Rejection")

phi_subset_idx <- sample(1:3108, size = 10)

phi_samples_subset <- phi_samples[, phi_subset_idx]
```

```{r}
plot(phi_samples_subset)
```

```{r}
gelman.diag(phi_samples_subset)
```



## Inference

```{r}
beta_samples_matrix <- rbind(chain1$samples$beta, chain2$samples$beta, chain3$samples$beta)

colnames(beta_samples_matrix) <- colnames(chain1$X)
```

```{r}
(beta_inference <- round(t(apply(beta_samples_matrix, 2, quantile, c(0.5, 0.025, 0.975))),5))
```

Net Effect interpretation: what if each variable in a group (flood risk variables, SVIs, air pollution variables) increased by 1 standard deviation? What is the resulting change in the CHD prevalence?

```{r}
row.names(beta_inference)
```

```{r}

sum(beta_inference[2:7, 1])
sum(beta_inference[2:22, 1])
sum(beta_inference[23:38, 1])
sum(beta_inference[39:44, 1])

```

List of significant beta coefficients: 

```{r}
colnames(beta_samples_matrix)[sign(beta_inference[, 2]) == sign(beta_inference[, 3])]
```

## Presenting the Results

Retrieving the standard deviation used to scale the covariates

```{r}
fhs_model_df <- readRDS(here("intermediary_data/fhs_model_df_sw_states_census_tract.rds"))
```

```{r}
X <- fhs_model_df[, 14:(ncol(fhs_model_df) - 1)]

X <- X[, names(X) != "pct_floodfactor1"]

X <- as.matrix(X)



X           <- scale(X) # Scale covariates
# X[is.na(X)] <- 0        # Fill in missing values with the mean
```

```{r}
(covariate_sds <- attr(X, "scaled:scale"))
```

Rescaling beta_inference (except the intercept)

```{r}
beta_inference_scaled <- beta_inference

for (i in 2:nrow(beta_inference)) {
  
  beta_inference_scaled[i, ] <- beta_inference_scaled[i, ] / covariate_sds[i - 1]
  
}
```

```{r}
beta_inference_scaled
```

Showing just the results for the significant coefficients

```{r}
beta_inference_scaled[sign(beta_inference_scaled[, 2]) == sign(beta_inference_scaled[, 3]), ]
```

```{r}
round(beta_inference_scaled[sign(beta_inference_scaled[, 2]) == sign(beta_inference_scaled[, 3]), ], digits = 3)
```

Multiplying by factor of 10, for more interpretability

```{r}
round((beta_inference_scaled * 10)[sign(beta_inference_scaled[, 2]) == sign(beta_inference_scaled[, 3]), ], digits = 2)
```



### Boxplots for the posterior distribution of coefficients

Scaling the posterior distributions of coefficients

```{r}
beta_samples_scaled <- beta_samples_matrix

for (j in 2:ncol(beta_samples_matrix)) {
  
  beta_samples_scaled[, j] <- beta_samples_scaled[, j] / covariate_sds[j - 1]
  
}
```

```{r}
beta_samples_scaled_10 <- beta_samples_scaled * 10
```

```{r}
round(t(apply(beta_samples_scaled_10, 2, quantile, c(0.5, 0.025, 0.975))),2)
```

```{r}
boxplot(beta_samples_scaled_10)
```



```{r}
boxplot(beta_samples_scaled_10[, 2:22])
boxplot(beta_samples_scaled_10[, 23:44])


```

```{r}
boxplot(beta_samples_matrix[, 2:22])
abline(h = 0, col = "red")

boxplot(beta_samples_matrix[, 23:45])
abline(h = 0, col = "Red")
```



### Boxplots for the posterior distribution of coefficients, in ggplot

```{r}
fl_coef_post <- stack(as.data.frame(beta_samples_matrix[, 2:22]))


```

```{r}
ggplot(fl_coef_post) + 
  geom_boxplot(aes(x = ind, y = values)) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1), axis.title.x = element_blank(), axis.title.y = element_blank(), 
        axis.text=element_text(size=12), 
        plot.margin = margin(5.5, 5.5, 5.5, 20)) + 
  geom_vline(xintercept = c(6.5, 12.5), col = "blue") + 
  geom_hline(yintercept = 0, col = "red") + 
  annotate(geom = "text", x = 3.5, y = 20, label = "Percentage of Properties\nat Risk", 
           col = "blue", size = 4.5) + 
  annotate(geom = "text", x = 9.5, y = 20, label = "Average Risk Score\nof Properties", 
           col = "blue", size = 4.5) + 
  annotate(geom = "text", x = 17, y = 20, label = "Percent of Properties with Risk Score", 
           col = "blue", size = 4.5) +
  scale_x_discrete(labels = c("Certain, 2020", "Certain, 2050", 
                              "Substantial, 2020", "Substantial, 2050",
                              "Any, 2020", "Any, 2050",
                              "All", "All except score 1", 
                              "With Substantial Risk", "With Any Risk", 
                              "In SFHA", "Not in SFHA", 
                              "Score 2", "Score 3", "Score 4", "Score 5", 
                              "Score 6", "Score 7", "Score 8", "Score 9", 
                              "Score 10"))
```

```{r}
other_coef_post <- stack(as.data.frame(beta_samples_matrix[, 23:45]))
```

```{r}
ggplot(other_coef_post) + 
  geom_boxplot(aes(x = ind, y = values)) + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1), axis.title.x = element_blank(), axis.title.y = element_blank(), 
        axis.text=element_text(size=12), 
        plot.margin = margin(5.5, 5.5, 5.5, 20)) +
  geom_vline(xintercept = c(16.5, 22.5), col = "blue") + 
  geom_hline(yintercept = 0, col = "red") +
  annotate(geom = "text", x = 8.5, y = 1.5, label = "Social Vulnerability Index", 
           col = "blue", size = 4.5) + 
  annotate(geom = "text", x = 19.5, y = 1.5, label = "Air Pollution", 
           col = "blue", size = 4.5) +
    scale_x_discrete(labels = c("Poverty", "Unemployed", "Per Capita Income", "No High School", 
                                "65 or Over", "17 or Under", "Disability", 
                                "Single-Parent", "Minority", "Poor English", 
                                "Multi-Unit", "Mobile", "Crowded", 
                                "No Vehicle", "Group Quarters", "Uninsured", 
                                "CO", "NO2", "O3", "PM10", "PM2.5", "SO2", 
                                "Smoking"))
  
```


